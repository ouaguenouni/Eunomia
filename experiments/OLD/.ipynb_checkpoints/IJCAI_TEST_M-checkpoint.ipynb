{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf609d15-3374-4a11-b70d-ec4022f5174e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Eunomia'...\n",
      "remote: Enumerating objects: 532, done.\u001b[K\n",
      "remote: Counting objects: 100% (532/532), done.\u001b[K\n",
      "remote: Compressing objects: 100% (204/204), done.\u001b[K\n",
      "remote: Total 532 (delta 396), reused 458 (delta 322), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (532/532), 3.49 MiB | 2.28 MiB/s, done.\n",
      "Resolving deltas: 100% (396/396), done.\n",
      "Requirement already satisfied: torch in /home/mohamed/miniconda3/lib/python3.9/site-packages (from -r Eunomia/requirements.txt (line 1)) (1.11.0)\n",
      "Requirement already satisfied: pyro-ppl in /home/mohamed/miniconda3/lib/python3.9/site-packages (from -r Eunomia/requirements.txt (line 2)) (1.8.6)\n",
      "Requirement already satisfied: cvxpy in /home/mohamed/miniconda3/lib/python3.9/site-packages (from -r Eunomia/requirements.txt (line 3)) (1.1.18)\n",
      "Requirement already satisfied: typing_extensions in /home/mohamed/miniconda3/lib/python3.9/site-packages (from torch->-r Eunomia/requirements.txt (line 1)) (4.8.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /home/mohamed/miniconda3/lib/python3.9/site-packages (from pyro-ppl->-r Eunomia/requirements.txt (line 2)) (1.26.2)\n",
      "Requirement already satisfied: tqdm>=4.36 in /home/mohamed/miniconda3/lib/python3.9/site-packages (from pyro-ppl->-r Eunomia/requirements.txt (line 2)) (4.62.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/mohamed/miniconda3/lib/python3.9/site-packages (from pyro-ppl->-r Eunomia/requirements.txt (line 2)) (3.3.0)\n",
      "Requirement already satisfied: pyro-api>=0.1.1 in /home/mohamed/miniconda3/lib/python3.9/site-packages (from pyro-ppl->-r Eunomia/requirements.txt (line 2)) (0.1.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/mohamed/miniconda3/lib/python3.9/site-packages (from cvxpy->-r Eunomia/requirements.txt (line 3)) (1.11.3)\n",
      "Requirement already satisfied: ecos>=2 in /home/mohamed/miniconda3/lib/python3.9/site-packages (from cvxpy->-r Eunomia/requirements.txt (line 3)) (2.0.10)\n",
      "Requirement already satisfied: scs>=1.1.6 in /home/mohamed/miniconda3/lib/python3.9/site-packages (from cvxpy->-r Eunomia/requirements.txt (line 3)) (3.1.0)\n",
      "Requirement already satisfied: osqp>=0.4.1 in /home/mohamed/miniconda3/lib/python3.9/site-packages (from cvxpy->-r Eunomia/requirements.txt (line 3)) (0.6.2.post4)\n",
      "Requirement already satisfied: qdldl in /home/mohamed/miniconda3/lib/python3.9/site-packages (from osqp>=0.4.1->cvxpy->-r Eunomia/requirements.txt (line 3)) (0.1.5.post0)\n"
     ]
    }
   ],
   "source": [
    "!rm -rf Eunomia\n",
    "!git clone https://github.com/ouaguenouni/Eunomia\n",
    "!pip install -r Eunomia/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3abe93fb-ed5a-4118-9efd-7297135edd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from Eunomia.preferences import *\n",
    "from Eunomia.additive_functions import *\n",
    "from Eunomia.alternatives import *\n",
    "from Eunomia.sampling import *\n",
    "from Eunomia.mcmc import *\n",
    "from Eunomia.degree import *\n",
    "from Eunomia.experiments import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f047e255-1b7c-478d-96cf-b4f87f1cdc6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e83ae8-91c1-4721-b8be-bf3789a45c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering the results in:  SX_IJCAI_M/2024-01-10/iter-0_n-8_k-2_m-2_sigma_w-0.1_sigma_p-0.1_n_samples-1500.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|████████████████████████████| 2000/2000 [00:41, 48.19it/s, step size=4.60e-01, acc. prob=0.893]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diag:  {'sigma': OrderedDict([('n_eff', tensor(1889.0231)), ('r_hat', tensor(0.9994))]), 'w': OrderedDict([('n_eff', tensor([1792.0217, 2163.9048, 1727.3032, 1360.8312, 1716.1515, 1570.0922,\n",
      "        1967.4713, 2237.5127, 2285.9871, 2473.8828, 2634.6074, 2234.9978,\n",
      "        1456.4183, 2829.6733, 1325.1003, 1469.0986, 1825.4655, 1302.1434,\n",
      "        2523.2178, 2812.0168, 1499.6768, 1587.0148, 2648.2214, 2306.9521,\n",
      "        1842.6719, 1594.5825, 1536.9441, 2336.1018, 2448.7734, 1998.1787,\n",
      "        1607.9410, 1562.8571, 1532.4666, 1539.6947, 1700.5157, 1588.7565])), ('r_hat', tensor([1.0005, 1.0012, 0.9996, 0.9994, 0.9996, 1.0017, 0.9998, 0.9994, 1.0013,\n",
      "        0.9994, 0.9993, 0.9999, 0.9993, 0.9995, 0.9995, 0.9995, 0.9995, 0.9999,\n",
      "        0.9995, 1.0000, 0.9997, 1.0004, 0.9995, 0.9993, 0.9998, 1.0006, 1.0025,\n",
      "        0.9997, 0.9999, 1.0030, 1.0008, 0.9995, 0.9994, 0.9995, 1.0013, 0.9994]))]), 'divergences': {'chain 0': [1390]}, 'acceptance rate': {'chain 0': 1.0}}\n",
      "Registering the results in:  SX_IJCAI_M/2024-01-10/iter-0_n-8_k-2_m-3_sigma_w-0.1_sigma_p-0.1_n_samples-1500.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|████████████████████████████| 2000/2000 [00:40, 49.52it/s, step size=5.09e-01, acc. prob=0.876]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diag:  {'sigma': OrderedDict([('n_eff', tensor(1636.4209)), ('r_hat', tensor(0.9994))]), 'w': OrderedDict([('n_eff', tensor([2374.7354, 3544.1370, 2852.2683, 3854.8916, 1506.5333, 2663.6416,\n",
      "        2125.9802, 3567.3408, 2655.0310, 2291.4104, 1817.5167, 2476.7356,\n",
      "        1761.1931, 2895.0830, 2149.2668, 2653.2568, 2940.7966, 2048.8374,\n",
      "        2444.7810, 3058.9978, 3081.7659, 3355.6140, 1573.8237, 1969.7905,\n",
      "        2172.9053, 1801.2661, 2489.7842, 3506.2810, 2077.3667, 2649.0247,\n",
      "        3112.9331, 2297.0063, 2948.6367, 2817.8960, 2114.1665, 2416.4453])), ('r_hat', tensor([1.0002, 0.9996, 0.9993, 0.9995, 0.9995, 1.0007, 1.0004, 1.0007, 0.9994,\n",
      "        0.9995, 0.9994, 0.9994, 0.9994, 0.9994, 0.9995, 0.9995, 0.9995, 0.9994,\n",
      "        0.9998, 0.9998, 0.9997, 0.9993, 0.9994, 1.0010, 1.0005, 0.9997, 0.9995,\n",
      "        0.9994, 0.9995, 0.9999, 1.0000, 1.0001, 0.9994, 0.9993, 0.9993, 1.0004]))]), 'divergences': {'chain 0': [360, 1122, 1184, 1185, 1353]}, 'acceptance rate': {'chain 0': 0.998}}\n",
      "Registering the results in:  SX_IJCAI_M/2024-01-10/iter-0_n-8_k-2_m-4_sigma_w-0.1_sigma_p-0.1_n_samples-1500.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|████████████████████████████| 2000/2000 [00:58, 34.03it/s, step size=4.13e-01, acc. prob=0.886]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diag:  {'sigma': OrderedDict([('n_eff', tensor(1766.0234)), ('r_hat', tensor(0.9995))]), 'w': OrderedDict([('n_eff', tensor([1918.2887, 2146.4788, 1656.0674, 1917.1061, 2029.0433, 1657.9333,\n",
      "        2045.1366, 1788.1034, 2226.8108, 1590.0653, 2137.5374, 2184.4067,\n",
      "        1556.5889, 2187.5884, 1361.9553, 1577.2065, 1785.1825, 1853.9478,\n",
      "        1836.6753, 2144.9492, 2076.6389, 1921.5750, 1643.1631, 2668.2134,\n",
      "        2161.3142, 2455.4648, 2245.6758, 2223.7153, 1991.1395, 2134.1843,\n",
      "        2202.4551, 2385.2161, 1722.5928, 2147.4243, 2111.1147, 2121.6914])), ('r_hat', tensor([1.0002, 0.9994, 1.0003, 0.9997, 0.9994, 0.9994, 0.9996, 1.0006, 1.0057,\n",
      "        0.9995, 0.9995, 0.9993, 0.9994, 0.9994, 1.0013, 0.9999, 0.9995, 0.9994,\n",
      "        0.9995, 0.9995, 0.9993, 0.9996, 1.0007, 1.0005, 0.9994, 0.9993, 0.9993,\n",
      "        0.9993, 0.9994, 0.9995, 0.9993, 0.9994, 0.9999, 0.9998, 0.9997, 0.9994]))]), 'divergences': {'chain 0': [1, 93, 177, 272, 312, 313, 364, 508, 509, 643, 692, 765, 849, 975, 1158, 1464]}, 'acceptance rate': {'chain 0': 0.9966666666666667}}\n",
      "Registering the results in:  SX_IJCAI_M/2024-01-10/iter-0_n-8_k-2_m-5_sigma_w-0.1_sigma_p-0.1_n_samples-1500.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   9%|██▋                          | 182/2000 [00:06, 22.01it/s, step size=1.59e-01, acc. prob=0.774]"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "TEST_NAME = \"SX_IJCAI_M\"\n",
    "REPLACE = False\n",
    "\n",
    "n = 8\n",
    "sigma_weights = 1\n",
    "sigma_w_vals = np.linspace(1e-3, 1e1, 25)\n",
    "sigma_p_vals =  np.linspace(1e-3, 1e1, 25)\n",
    "n_samples = 1500\n",
    "k=2\n",
    "\n",
    "for iter_ in range(10):\n",
    "    for sigma_w, sigma_p in zip([1e-1], [1e-1]):\n",
    "        for m in list(i for i in range(2, 2**n, 1)):\n",
    "            run_d = {\n",
    "                \"iter\":iter_,\n",
    "                \"n\": n,\n",
    "                \"k\": k,\n",
    "                \"m\": m,\n",
    "                \"sigma_w\": float(sigma_w),\n",
    "                \"sigma_p\": float(sigma_p),\n",
    "                \"n_samples\": n_samples\n",
    "            }\n",
    "            found = find_experiment_file(run_d, TEST_NAME)\n",
    "            if found:\n",
    "                date = found\n",
    "                print(f\"Found file: {file_name}\")\n",
    "                if REPLACE:\n",
    "                    print('Replacing it...')\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                file_name = compute_experiment_file_name(run_d, TEST_NAME)\n",
    "                print(\"Registering the results in: \", file_name)\n",
    "            ####\n",
    "            theta = generate_additive_theta(n, k)\n",
    "            weights = generate_normal_weights(theta, sigma_weights)\n",
    "            alternatives = generate_random_alternatives_matrix(m, n)\n",
    "            ranks = compute_ws_ranks(alternatives, theta, weights)\n",
    "            t_sv = compute_semivalues(n, theta, weights, lambda x:1)\n",
    "            preferences = PreferenceModel(alternatives, ranks)\n",
    "            data = preferences.generate_preference_matrix(theta)\n",
    "            data = torch.tensor(data).float()\n",
    "            t = time.time()\n",
    "            model = posterior_sampling_model(data, sigma_w=sigma_w, sigma_p=sigma_p)\n",
    "            diag, sampled_weights, sigmas = sample_model(model, data, \"w\", \"sigma\", warmup_steps=500, num_samples=n_samples, return_diag=True)\n",
    "            t = time.time() - t\n",
    "            accs_d = get_acc_distribution(data, sampled_weights, sigmas)\n",
    "            predicted_rankings = [np.argsort(compute_semivalues(n, theta, weights, lambda x:1))[::-1] for weights in sampled_weights]\n",
    "            kt_d = get_kt_distribution(predicted_rankings, np.argsort(t_sv))\n",
    "            ###\n",
    "            \n",
    "            file_path = record_experiment_results(run_d, TEST_NAME)\n",
    "            \n",
    "            run_d[\"time\"] = t\n",
    "            run_d[\"weights\"] = weights.tolist()\n",
    "            run_d[\"predicted_rankings\"] = [i.tolist() for i in predicted_rankings]\n",
    "            run_d[\"accuracy_distribution\"] = [i.tolist() for i in accs_d]\n",
    "            run_d[\"kt_d\"] = [i.tolist() for i in kt_d]\n",
    "            run_d[\"acceptance_rate\"] = diag[\"acceptance rate\"][\"chain 0\"]\n",
    "            run_d[\"w_eff\"] = [float(i) for i in diag[\"w\"][\"n_eff\"].numpy()]\n",
    "            run_d[\"w_rhat\"] = [float(i) for i in diag[\"w\"][\"r_hat\"].numpy()]\n",
    "            \n",
    "            print(\"diag: \", diag)\n",
    "            with open(file_path, 'w') as file:\n",
    "                yaml.dump(run_d, file, default_flow_style=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f408ad62-8944-474a-8e0d-c6fd22cf1b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
